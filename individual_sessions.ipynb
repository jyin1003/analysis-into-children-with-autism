{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_directory = \"./vis_project_data/\"\n",
    "\n",
    "# Default weights adjusted to match results\n",
    "cog_weights = np.array([0, -1, 1, 2, 2, 3, 5])\n",
    "so_weights = np.array([-1, 0, 1, 2, 2, 3, 5])\n",
    "\n",
    "\n",
    "# Types of sessions/files:\n",
    "session_types = [\"cog\", \"so\"]\n",
    "whatdoors = [\"indoor\", \"outdoor\"]\n",
    "whichs = [\"base\", \"inter\"]\n",
    "ca_peer_list = [\"albert\", \"barry\", \"chris\", \"dana\"]\n",
    "\n",
    "# Combine to single itteratable list\n",
    "combined_scenarios = [\n",
    "    (ses_type, whatdoor, which)\n",
    "    for ses_type in session_types\n",
    "    for whatdoor in whatdoors\n",
    "    for which in whichs\n",
    "]\n",
    "\n",
    "data_directory = \"./vis_project_data/\"\n",
    "\n",
    "# Default weights adjusted to match results\n",
    "cog_weights = np.array([0, -1, 1, 2, 2, 3, 5])\n",
    "so_weights = np.array([-1, 0, 1, 2, 2, 3, 5])\n",
    "\n",
    "\n",
    "# Types of sessions/files:\n",
    "session_types = [\"cog\", \"so\"]\n",
    "whatdoors = [\"indoor\", \"outdoor\"]\n",
    "whichs = [\"base\", \"inter\"]\n",
    "ca_peer_list = [\"albert\", \"barry\", \"chris\", \"dana\"]\n",
    "\n",
    "# Combine to single itteratable list\n",
    "combined_scenarios = [\n",
    "    (ses_type, whatdoor, which)\n",
    "    for ses_type in session_types\n",
    "    for whatdoor in whatdoors\n",
    "    for which in whichs\n",
    "]\n",
    "\n",
    "def unique_pairs():\n",
    "    \"\"\"Returns list of unique ca/peer pairs\"\"\"\n",
    "    all_files = glob.glob(data_directory + \"/*.dtx\")\n",
    "    list = []\n",
    "    for file in all_files:\n",
    "        t = file.split(\"-\")\n",
    "        list.append([t[4], t[5]])\n",
    "\n",
    "    return np.unique(list, axis=0)\n",
    "\n",
    "def get_files(ca, peer):\n",
    "    files = []\n",
    "    for ses_type, whatdoor, which in combined_scenarios:\n",
    "        file_pattern = f\"{ses_type}-*-{which}-*-{ca}-{peer}-{whatdoor}.dtx\"\n",
    "        files.extend(glob.glob(data_directory + file_pattern))\n",
    "    return files\n",
    "\n",
    "# get trained dyads\n",
    "def get_trained_pair_files():\n",
    "    ca_peer_list = unique_pairs()\n",
    "    file_list = []\n",
    "    for pair in ca_peer_list:\n",
    "        files = get_files(pair[0], pair[1])\n",
    "        if pair[1][0].upper() >= 'U' and pair[1][0].upper() <= 'Z':\n",
    "            file_list.append(files)\n",
    "    return file_list\n",
    "\n",
    "# get untrained dyads\n",
    "def get_untrained_pair_files():\n",
    "    ca_peer_list = unique_pairs()\n",
    "    file_list = []\n",
    "    for pair in ca_peer_list:\n",
    "        files = get_files(pair[0], pair[1])\n",
    "        if pair[1][0].upper() >= 'L' and pair[1][0].upper() <= 'P':\n",
    "            file_list.append(files)\n",
    "    return file_list\n",
    "\n",
    "# returns all the trials in a list for a given CA and scenario\n",
    "def filter_ca_scenario(files, ses_type, which, ca, whatdoor):\n",
    "    filtered_files = []\n",
    "    for file_pair_list in files:\n",
    "        for file in file_pair_list:\n",
    "            file_name = file.split('\\\\')[-1]  # Extract the file name\n",
    "            components = file_name.split('-')      \n",
    "            #print(\"file components\")\n",
    "            #print(components)\n",
    "            if len(components) >= 7 and \\\n",
    "                components[0] == ses_type and \\\n",
    "                components[-1].startswith(whatdoor) and \\\n",
    "                components[2] == which and \\\n",
    "                components[4] == ca:\n",
    "                filtered_files.append(file)\n",
    "    #print(filtered_files)\n",
    "    return filtered_files\n",
    "\n",
    "#filter_ca_scenario(get_trained_pair_files(), \"cog\", \"base\", \"albert\", \"indoor\")\n",
    "\n",
    "def combined_score(filename, weights):\n",
    "    \"\"\"Calculates the 'score' for a single session/file.\n",
    "    Assumes total session duration is 360s, otherwise returns 'nan'.\n",
    "    This could be modified simply to also return other details of the session.\"\"\"\n",
    "    with open(filename, \"r\") as file:\n",
    "        score = 0.0\n",
    "        total_duration = 0.0\n",
    "        t_end_prev = 0.0\n",
    "        for count, line in enumerate(file.readlines()):\n",
    "            # print(count, line)\n",
    "            data = line.split(\",\", 4)\n",
    "            if count == 0:\n",
    "                continue\n",
    "            if line[0] == \"*\":\n",
    "                break\n",
    "\n",
    "            t_catagory = int(data[0])\n",
    "            t_beg = int(data[1])\n",
    "            t_end = int(data[2])\n",
    "\n",
    "            if t_beg != t_end_prev:\n",
    "                print(\"Error, missing time stamp?\")\n",
    "            t_end_prev = t_end\n",
    "\n",
    "            assert t_end >= t_beg\n",
    "            if count == 1:\n",
    "                assert t_beg == 0\n",
    "\n",
    "            duration = float(t_end - t_beg)\n",
    "            total_duration += duration\n",
    "            score += weights[t_catagory - 1] * duration\n",
    "        return score / total_duration\n",
    "    \n",
    "def get_ca_scenario_stats(files, ses_type):\n",
    "    if ses_type == \"so\":\n",
    "        weights = so_weights\n",
    "    else:\n",
    "        weights = cog_weights\n",
    "    scores = []\n",
    "    statistics = []\n",
    "    for file in files:\n",
    "        temp_score = combined_score(file, weights)\n",
    "        #print(temp_score)\n",
    "        scores.append(temp_score)\n",
    "    statistics.append(np.mean(scores))\n",
    "    sdev = np.std(scores, ddof=1)  # \"corrected\" sdev\n",
    "    statistics.append(sdev)\n",
    "    statistics.append(sdev / np.sqrt(len(scores)))\n",
    "    return statistics # returns mean, std, and standard error of mean\n",
    "\n",
    "files = filter_ca_scenario(get_trained_pair_files(), \"so\", \"base\", \"albert\", \"indoor\")\n",
    "get_ca_scenario_stats(files, \"so\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
